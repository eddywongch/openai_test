{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhgzjAIMtcpngtd6VYJ1ZR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eddywongch/openai_test/blob/main/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBf4V98jI4xL",
        "outputId": "4f201da0-84b6-4561-8074-52a5ec271c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai==0.28\n",
            "  Using cached openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.4)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.9.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.6.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Installing collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 0.27.0\n",
            "    Uninstalling openai-0.27.0:\n",
            "      Successfully uninstalled openai-0.27.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.1.8 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain-openai 0.1.8 requires openai<2.0.0,>=1.26.0, but you have openai 0.28.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E89BFs40YFje",
        "outputId": "4d6fd323-8b65-4da9-caa6-d5cb2da00f55"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: openai\n",
            "Version: 1.33.0\n",
            "Summary: The official Python library for the openai API\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: OpenAI <support@openai.com>\n",
            "License: \n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: anyio, distro, httpx, pydantic, sniffio, tqdm, typing-extensions\n",
            "Required-by: langchain-openai\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzH7nHB6KOXX",
        "outputId": "5f8a95f4-61ae-44d2-df16-10b7b534d7d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RjKm4Cl2LRox",
        "outputId": "0783a1b5-d943-47c8-b9bd-c33414ce3a51"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.20 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.20)\n",
            "Collecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Using cached langchain_core-0.1.52-py3-none-any.whl (302 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Using cached langsmith-0.0.92-py3-none-any.whl (56 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.3)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (3.0.0)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.22 (from langchain)\n",
            "  Using cached langchain_core-0.1.51-py3-none-any.whl (302 kB)\n",
            "  Using cached langchain_core-0.1.50-py3-none-any.whl (302 kB)\n",
            "  Using cached langchain_core-0.1.49-py3-none-any.whl (303 kB)\n",
            "  Using cached langchain_core-0.1.48-py3-none-any.whl (302 kB)\n",
            "  Using cached langchain_core-0.1.47-py3-none-any.whl (302 kB)\n",
            "  Using cached langchain_core-0.1.46-py3-none-any.whl (299 kB)\n",
            "  Using cached langchain_core-0.1.45-py3-none-any.whl (291 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Using cached langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "  Using cached langchain_core-0.1.43-py3-none-any.whl (289 kB)\n",
            "  Using cached langchain_core-0.1.42-py3-none-any.whl (287 kB)\n",
            "  Using cached langchain_core-0.1.41-py3-none-any.whl (278 kB)\n",
            "  Using cached langchain_core-0.1.40-py3-none-any.whl (276 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_core-0.1.39-py3-none-any.whl (276 kB)\n",
            "  Using cached langchain_core-0.1.38-py3-none-any.whl (279 kB)\n",
            "  Using cached langchain_core-0.1.37-py3-none-any.whl (274 kB)\n",
            "  Using cached langchain_core-0.1.36-py3-none-any.whl (273 kB)\n",
            "  Using cached langchain_core-0.1.35-py3-none-any.whl (273 kB)\n",
            "  Using cached langchain_core-0.1.34-py3-none-any.whl (271 kB)\n",
            "  Using cached langchain_core-0.1.33-py3-none-any.whl (269 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (3.7.1)\n",
            "  Using cached langchain_core-0.1.32-py3-none-any.whl (260 kB)\n",
            "  Using cached langchain_core-0.1.31-py3-none-any.whl (258 kB)\n",
            "  Using cached langchain_core-0.1.30-py3-none-any.whl (256 kB)\n",
            "  Using cached langchain_core-0.1.29-py3-none-any.whl (252 kB)\n",
            "  Using cached langchain_core-0.1.28-py3-none-any.whl (252 kB)\n",
            "  Using cached langchain_core-0.1.27-py3-none-any.whl (250 kB)\n",
            "  Using cached langchain_core-0.1.26-py3-none-any.whl (246 kB)\n",
            "  Using cached langchain_core-0.1.25-py3-none-any.whl (242 kB)\n",
            "  Using cached langchain_core-0.1.24-py3-none-any.whl (241 kB)\n",
            "  Using cached langchain_core-0.1.23-py3-none-any.whl (241 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Using cached langsmith-0.0.87-py3-none-any.whl (55 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.22->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.22->langchain) (1.2.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.1.76\n",
            "    Uninstalling langsmith-0.1.76:\n",
            "      Successfully uninstalled langsmith-0.1.76\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.2.5\n",
            "    Uninstalling langchain-core-0.2.5:\n",
            "      Successfully uninstalled langchain-core-0.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-openai 0.1.8 requires langchain-core<0.3,>=0.2.2, but you have langchain-core 0.1.23 which is incompatible.\n",
            "langchain-text-splitters 0.2.1 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.1.23 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.1.23 langsmith-0.0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vX28RodwLyzp",
        "outputId": "465739f0-7477-4237-f017-e6f12c03b9bc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.21 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.23)\n",
            "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.0.87)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.21->langchain-community) (2.7.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.21->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2,>=0.1.21->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2,>=0.1.21->langchain-community) (2.18.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neo4j"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKTADg5uMFhp",
        "outputId": "12101cd4-8bd1-47f9-b2a2-3bc62424d2c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: neo4j in /usr/local/lib/python3.10/dist-packages (5.21.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from neo4j) (2023.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z79tLnWrN3x-",
        "outputId": "66e841d9-b985-4935-fc7b-a1761abbfc29"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.8)\n",
            "Collecting langchain-core<0.3,>=0.2.2 (from langchain-openai)\n",
            "  Using cached langchain_core-0.2.5-py3-none-any.whl (314 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.33.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (1.33)\n",
            "Collecting langsmith<0.2.0,>=0.1.66 (from langchain-core<0.3,>=0.2.2->langchain-openai)\n",
            "  Using cached langsmith-0.1.76-py3-none-any.whl (124 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (2.7.3)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.2->langchain-openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.26.0->langchain-openai) (4.12.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (2024.6.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.26.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.66->langchain-core<0.3,>=0.2.2->langchain-openai) (3.10.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.4 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.2->langchain-openai) (2.18.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Installing collected packages: langsmith, langchain-core\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.0.87\n",
            "    Uninstalling langsmith-0.0.87:\n",
            "      Successfully uninstalled langsmith-0.0.87\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.1.23\n",
            "    Uninstalling langchain-core-0.1.23:\n",
            "      Successfully uninstalled langchain-core-0.1.23\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain 0.1.7 requires langchain-core<0.2,>=0.1.22, but you have langchain-core 0.2.5 which is incompatible.\n",
            "langchain 0.1.7 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.76 which is incompatible.\n",
            "langchain-community 0.0.20 requires langchain-core<0.2,>=0.1.21, but you have langchain-core 0.2.5 which is incompatible.\n",
            "langchain-community 0.0.20 requires langsmith<0.1,>=0.0.83, but you have langsmith 0.1.76 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed langchain-core-0.2.5 langsmith-0.1.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFtvNjerbgMl",
        "outputId": "144eadca-b362-4494-b9f1-a2d8299ea10d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==1.4.0\n",
            "aiohttp==3.9.5\n",
            "aiosignal==1.3.1\n",
            "alabaster==0.7.16\n",
            "albumentations==1.3.1\n",
            "altair==4.2.2\n",
            "annotated-types==0.7.0\n",
            "anyio==3.7.1\n",
            "argon2-cffi==23.1.0\n",
            "argon2-cffi-bindings==21.2.0\n",
            "array_record==0.5.1\n",
            "arviz==0.15.1\n",
            "astropy==5.3.4\n",
            "astunparse==1.6.3\n",
            "async-timeout==4.0.3\n",
            "atpublic==4.1.0\n",
            "attrs==23.2.0\n",
            "audioread==3.0.1\n",
            "autograd==1.6.2\n",
            "Babel==2.15.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.12.3\n",
            "bidict==0.23.1\n",
            "bigframes==1.8.0\n",
            "bleach==6.1.0\n",
            "blinker==1.4\n",
            "blis==0.7.11\n",
            "blosc2==2.0.0\n",
            "bokeh==3.3.4\n",
            "bqplot==0.12.43\n",
            "branca==0.7.2\n",
            "build==1.2.1\n",
            "CacheControl==0.14.0\n",
            "cachetools==5.3.3\n",
            "catalogue==2.0.10\n",
            "certifi==2024.6.2\n",
            "cffi==1.16.0\n",
            "chardet==5.2.0\n",
            "charset-normalizer==3.3.2\n",
            "chex==0.1.86\n",
            "click==8.1.7\n",
            "click-plugins==1.1.1\n",
            "cligj==0.7.2\n",
            "cloudpathlib==0.16.0\n",
            "cloudpickle==2.2.1\n",
            "cmake==3.27.9\n",
            "cmdstanpy==1.2.3\n",
            "colorcet==3.1.0\n",
            "colorlover==0.3.0\n",
            "colour==0.1.5\n",
            "community==1.0.0b1\n",
            "confection==0.1.5\n",
            "cons==0.4.6\n",
            "contextlib2==21.6.0\n",
            "contourpy==1.2.1\n",
            "cryptography==42.0.7\n",
            "cuda-python==12.2.1\n",
            "cudf-cu12 @ https://pypi.nvidia.com/cudf-cu12/cudf_cu12-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl#sha256=57366e7ef09dc63e0b389aff20df6c37d91e2790065861ee31a4720149f5b694\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda12x==12.2.0\n",
            "cvxopt==1.3.2\n",
            "cvxpy==1.3.4\n",
            "cycler==0.12.1\n",
            "cymem==2.0.8\n",
            "Cython==3.0.10\n",
            "dask==2023.8.1\n",
            "dataclasses-json==0.6.7\n",
            "datascience==0.17.6\n",
            "db-dtypes==1.2.0\n",
            "dbus-python==1.2.18\n",
            "debugpy==1.6.6\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "distributed==2023.8.1\n",
            "distro==1.7.0\n",
            "dlib==19.24.4\n",
            "dm-tree==0.1.8\n",
            "docstring_parser==0.16\n",
            "docutils==0.18.1\n",
            "dopamine_rl==4.0.9\n",
            "duckdb==0.10.3\n",
            "earthengine-api==0.1.405\n",
            "easydict==1.13\n",
            "ecos==2.0.13\n",
            "editdistance==0.6.2\n",
            "eerepr==0.0.4\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl#sha256=86cc141f63942d4b2c5fcee06630fd6f904788d2f0ab005cce45aadb8fb73889\n",
            "entrypoints==0.4\n",
            "et-xmlfile==1.1.0\n",
            "etils==1.7.0\n",
            "etuples==0.3.9\n",
            "exceptiongroup==1.2.1\n",
            "fastai==2.7.15\n",
            "fastcore==1.5.43\n",
            "fastdownload==0.0.7\n",
            "fastjsonschema==2.19.1\n",
            "fastprogress==1.0.3\n",
            "fastrlock==0.8.2\n",
            "filelock==3.14.0\n",
            "fiona==1.9.6\n",
            "firebase-admin==5.3.0\n",
            "Flask==2.2.5\n",
            "flatbuffers==24.3.25\n",
            "flax==0.8.4\n",
            "folium==0.14.0\n",
            "fonttools==4.53.0\n",
            "frozendict==2.4.4\n",
            "frozenlist==1.4.1\n",
            "fsspec==2023.6.0\n",
            "future==0.18.3\n",
            "gast==0.5.4\n",
            "gcsfs==2023.6.0\n",
            "GDAL==3.6.4\n",
            "gdown==5.1.0\n",
            "geemap==0.32.1\n",
            "gensim==4.3.2\n",
            "geocoder==1.38.1\n",
            "geographiclib==2.0\n",
            "geopandas==0.13.2\n",
            "geopy==2.3.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-ai-generativelanguage==0.6.4\n",
            "google-api-core==2.11.1\n",
            "google-api-python-client==2.84.0\n",
            "google-auth==2.27.0\n",
            "google-auth-httplib2==0.1.1\n",
            "google-auth-oauthlib==1.2.0\n",
            "google-cloud-aiplatform==1.52.0\n",
            "google-cloud-bigquery==3.21.0\n",
            "google-cloud-bigquery-connection==1.12.1\n",
            "google-cloud-bigquery-storage==2.25.0\n",
            "google-cloud-core==2.3.3\n",
            "google-cloud-datastore==2.15.2\n",
            "google-cloud-firestore==2.11.1\n",
            "google-cloud-functions==1.13.3\n",
            "google-cloud-iam==2.15.0\n",
            "google-cloud-language==2.13.3\n",
            "google-cloud-resource-manager==1.12.3\n",
            "google-cloud-storage==2.8.0\n",
            "google-cloud-translate==3.11.3\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz#sha256=e477513d97f1eba039896512a8c15a84b455b474f513cac51489c290037b5ef4\n",
            "google-crc32c==1.5.0\n",
            "google-generativeai==0.5.4\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==2.7.0\n",
            "googleapis-common-protos==1.63.1\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.20.3\n",
            "greenlet==3.0.3\n",
            "grpc-google-iam-v1==0.13.0\n",
            "grpcio==1.64.1\n",
            "grpcio-status==1.48.2\n",
            "gspread==6.0.2\n",
            "gspread-dataframe==3.3.1\n",
            "gym==0.25.2\n",
            "gym-notices==0.0.8\n",
            "h11==0.14.0\n",
            "h5netcdf==1.3.0\n",
            "h5py==3.9.0\n",
            "holidays==0.50\n",
            "holoviews==1.17.1\n",
            "html5lib==1.1\n",
            "httpcore==1.0.5\n",
            "httpimport==1.3.1\n",
            "httplib2==0.22.0\n",
            "httpx==0.27.0\n",
            "huggingface-hub==0.23.2\n",
            "humanize==4.7.0\n",
            "hyperopt==0.2.7\n",
            "ibis-framework==8.0.0\n",
            "idna==3.7\n",
            "imageio==2.31.6\n",
            "imageio-ffmpeg==0.5.1\n",
            "imagesize==1.4.1\n",
            "imbalanced-learn==0.10.1\n",
            "imgaug==0.4.0\n",
            "immutabledict==4.2.0\n",
            "importlib_metadata==7.1.0\n",
            "importlib_resources==6.4.0\n",
            "imutils==0.5.4\n",
            "inflect==7.0.0\n",
            "iniconfig==2.0.0\n",
            "intel-openmp==2023.2.4\n",
            "ipyevents==2.0.2\n",
            "ipyfilechooser==0.6.0\n",
            "ipykernel==5.5.6\n",
            "ipyleaflet==0.18.2\n",
            "ipython==7.34.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.5.0\n",
            "ipytree==0.2.2\n",
            "ipywidgets==7.7.1\n",
            "itsdangerous==2.2.0\n",
            "jax==0.4.26\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda12/jaxlib-0.4.26+cuda12.cudnn89-cp310-cp310-manylinux2014_x86_64.whl#sha256=813cf1fe3e7ca4dbf5327d6e7b4fc8521e92d8bba073ee645ae0d5d036a25750\n",
            "jeepney==0.7.1\n",
            "jellyfish==1.0.4\n",
            "jieba==0.42.1\n",
            "Jinja2==3.1.4\n",
            "joblib==1.4.2\n",
            "jsonpatch==1.33\n",
            "jsonpickle==3.0.4\n",
            "jsonpointer==3.0.0\n",
            "jsonschema==4.19.2\n",
            "jsonschema-specifications==2023.12.1\n",
            "jupyter-client==6.1.12\n",
            "jupyter-console==6.1.0\n",
            "jupyter-server==1.24.0\n",
            "jupyter_core==5.7.2\n",
            "jupyterlab_pygments==0.3.0\n",
            "jupyterlab_widgets==3.0.11\n",
            "kaggle==1.6.14\n",
            "kagglehub==0.2.5\n",
            "keras==2.15.0\n",
            "keyring==23.5.0\n",
            "kiwisolver==1.4.5\n",
            "langchain==0.1.7\n",
            "langchain-community==0.0.20\n",
            "langchain-core==0.2.5\n",
            "langchain-openai==0.1.8\n",
            "langchain-text-splitters==0.2.1\n",
            "langcodes==3.4.0\n",
            "langsmith==0.1.76\n",
            "language_data==1.2.0\n",
            "launchpadlib==1.10.16\n",
            "lazr.restfulclient==0.14.4\n",
            "lazr.uri==1.0.6\n",
            "lazy_loader==0.4\n",
            "libclang==18.1.1\n",
            "librosa==0.10.2.post1\n",
            "lightgbm==4.1.0\n",
            "linkify-it-py==2.0.3\n",
            "llvmlite==0.41.1\n",
            "locket==1.0.0\n",
            "logical-unification==0.4.6\n",
            "lxml==4.9.4\n",
            "malloy==2023.1067\n",
            "marisa-trie==1.1.1\n",
            "Markdown==3.6\n",
            "markdown-it-py==3.0.0\n",
            "MarkupSafe==2.1.5\n",
            "marshmallow==3.21.3\n",
            "matplotlib==3.7.1\n",
            "matplotlib-inline==0.1.7\n",
            "matplotlib-venn==0.11.10\n",
            "mdit-py-plugins==0.4.1\n",
            "mdurl==0.1.2\n",
            "miniKanren==1.0.3\n",
            "missingno==0.5.2\n",
            "mistune==0.8.4\n",
            "mizani==0.9.3\n",
            "mkl==2023.2.0\n",
            "ml-dtypes==0.2.0\n",
            "mlxtend==0.22.0\n",
            "more-itertools==10.1.0\n",
            "moviepy==1.0.3\n",
            "mpmath==1.3.0\n",
            "msgpack==1.0.8\n",
            "multidict==6.0.5\n",
            "multipledispatch==1.0.0\n",
            "multitasking==0.0.11\n",
            "murmurhash==1.0.10\n",
            "music21==9.1.0\n",
            "mypy-extensions==1.0.0\n",
            "natsort==8.4.0\n",
            "nbclassic==1.1.0\n",
            "nbclient==0.10.0\n",
            "nbconvert==6.5.4\n",
            "nbformat==5.10.4\n",
            "neo4j==5.21.0\n",
            "nest-asyncio==1.6.0\n",
            "networkx==3.3\n",
            "nibabel==4.0.2\n",
            "nltk==3.8.1\n",
            "notebook==6.5.5\n",
            "notebook_shim==0.2.4\n",
            "numba==0.58.1\n",
            "numexpr==2.10.0\n",
            "numpy==1.25.2\n",
            "nvtx==0.2.10\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.2.2\n",
            "openai==1.33.0\n",
            "opencv-contrib-python==4.8.0.76\n",
            "opencv-python==4.8.0.76\n",
            "opencv-python-headless==4.10.0.82\n",
            "openpyxl==3.1.3\n",
            "opt-einsum==3.3.0\n",
            "optax==0.2.2\n",
            "orbax-checkpoint==0.4.4\n",
            "orjson==3.10.4\n",
            "osqp==0.6.2.post8\n",
            "packaging==23.2\n",
            "pandas==2.0.3\n",
            "pandas-datareader==0.10.0\n",
            "pandas-gbq==0.19.2\n",
            "pandas-stubs==2.0.3.230814\n",
            "pandocfilters==1.5.1\n",
            "panel==1.3.8\n",
            "param==2.1.0\n",
            "parso==0.8.4\n",
            "parsy==2.1\n",
            "partd==1.4.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.6\n",
            "peewee==3.17.5\n",
            "pexpect==4.9.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==9.4.0\n",
            "pip-tools==6.13.0\n",
            "platformdirs==4.2.2\n",
            "plotly==5.15.0\n",
            "plotnine==0.12.4\n",
            "pluggy==1.5.0\n",
            "polars==0.20.2\n",
            "pooch==1.8.1\n",
            "portpicker==1.5.2\n",
            "prefetch-generator==1.0.3\n",
            "preshed==3.0.9\n",
            "prettytable==3.10.0\n",
            "proglog==0.1.10\n",
            "progressbar2==4.2.0\n",
            "prometheus_client==0.20.0\n",
            "promise==2.3\n",
            "prompt_toolkit==3.0.45\n",
            "prophet==1.1.5\n",
            "proto-plus==1.23.0\n",
            "protobuf==3.20.3\n",
            "psutil==5.9.5\n",
            "psycopg2==2.9.9\n",
            "ptyprocess==0.7.0\n",
            "py-cpuinfo==9.0.0\n",
            "py4j==0.10.9.7\n",
            "pyarrow==14.0.2\n",
            "pyarrow-hotfix==0.6\n",
            "pyasn1==0.6.0\n",
            "pyasn1_modules==0.4.0\n",
            "pycocotools==2.0.7\n",
            "pycparser==2.22\n",
            "pydantic==2.7.3\n",
            "pydantic_core==2.18.4\n",
            "pydata-google-auth==1.8.2\n",
            "pydot==1.4.2\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "PyDrive2==1.6.3\n",
            "pyerfa==2.0.1.4\n",
            "pygame==2.5.2\n",
            "Pygments==2.16.1\n",
            "PyGObject==3.42.1\n",
            "PyJWT==2.3.0\n",
            "pymc==5.10.4\n",
            "pymystem3==0.2.0\n",
            "pynvjitlink-cu12==0.2.3\n",
            "PyOpenGL==3.1.7\n",
            "pyOpenSSL==24.1.0\n",
            "pyparsing==3.1.2\n",
            "pyperclip==1.8.2\n",
            "pyproj==3.6.1\n",
            "pyproject_hooks==1.1.0\n",
            "pyshp==2.3.1\n",
            "PySocks==1.7.1\n",
            "pytensor==2.18.6\n",
            "pytest==7.4.4\n",
            "python-apt @ file:///backend-container/containers/python_apt-0.0.0-cp310-cp310-linux_x86_64.whl#sha256=b209c7165d6061963abe611492f8c91c3bcef4b7a6600f966bab58900c63fefa\n",
            "python-box==7.1.1\n",
            "python-dateutil==2.8.2\n",
            "python-dotenv==1.0.1\n",
            "python-louvain==0.16\n",
            "python-slugify==8.0.4\n",
            "python-utils==3.8.2\n",
            "pytz==2023.4\n",
            "pyviz_comms==3.0.2\n",
            "PyWavelets==1.6.0\n",
            "PyYAML==6.0.1\n",
            "pyzmq==24.0.1\n",
            "qdldl==0.1.7.post2\n",
            "qudida==0.0.4\n",
            "ratelim==0.1.6\n",
            "referencing==0.35.1\n",
            "regex==2024.5.15\n",
            "requests==2.31.0\n",
            "requests-oauthlib==1.3.1\n",
            "requirements-parser==0.9.0\n",
            "rich==13.7.1\n",
            "rmm-cu12==24.4.0\n",
            "rpds-py==0.18.1\n",
            "rpy2==3.4.2\n",
            "rsa==4.9\n",
            "safetensors==0.4.3\n",
            "scikit-image==0.19.3\n",
            "scikit-learn==1.2.2\n",
            "scipy==1.11.4\n",
            "scooby==0.10.0\n",
            "scs==3.2.4.post2\n",
            "seaborn==0.13.1\n",
            "SecretStorage==3.3.1\n",
            "Send2Trash==1.8.3\n",
            "sentencepiece==0.1.99\n",
            "shapely==2.0.4\n",
            "simple_parsing==0.1.5\n",
            "six==1.16.0\n",
            "sklearn-pandas==2.2.0\n",
            "smart-open==6.4.0\n",
            "sniffio==1.3.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "soundfile==0.12.1\n",
            "soupsieve==2.5\n",
            "soxr==0.3.7\n",
            "spacy==3.7.4\n",
            "spacy-legacy==3.0.12\n",
            "spacy-loggers==1.0.5\n",
            "Sphinx==5.0.2\n",
            "sphinxcontrib-applehelp==1.0.8\n",
            "sphinxcontrib-devhelp==1.0.6\n",
            "sphinxcontrib-htmlhelp==2.0.5\n",
            "sphinxcontrib-jsmath==1.0.1\n",
            "sphinxcontrib-qthelp==1.0.7\n",
            "sphinxcontrib-serializinghtml==1.1.10\n",
            "SQLAlchemy==2.0.30\n",
            "sqlglot==20.11.0\n",
            "sqlparse==0.5.0\n",
            "srsly==2.4.8\n",
            "stanio==0.5.0\n",
            "statsmodels==0.14.2\n",
            "StrEnum==0.4.15\n",
            "sympy==1.12.1\n",
            "tables==3.8.0\n",
            "tabulate==0.9.0\n",
            "tbb==2021.12.0\n",
            "tblib==3.0.0\n",
            "tenacity==8.3.0\n",
            "tensorboard==2.15.2\n",
            "tensorboard-data-server==0.7.2\n",
            "tensorflow @ https://storage.googleapis.com/colab-tf-builds-public-09h6ksrfwbb9g9xv/tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl#sha256=a2ec79931350b378c1ef300ca836b52a55751acb71a433582508a07f0de57c42\n",
            "tensorflow-datasets==4.9.5\n",
            "tensorflow-estimator==2.15.0\n",
            "tensorflow-gcs-config==2.15.0\n",
            "tensorflow-hub==0.16.1\n",
            "tensorflow-io-gcs-filesystem==0.37.0\n",
            "tensorflow-metadata==1.15.0\n",
            "tensorflow-probability==0.23.0\n",
            "tensorstore==0.1.45\n",
            "termcolor==2.4.0\n",
            "terminado==0.18.1\n",
            "text-unidecode==1.3\n",
            "textblob==0.17.1\n",
            "tf-slim==1.1.0\n",
            "tf_keras==2.15.1\n",
            "thinc==8.2.3\n",
            "threadpoolctl==3.5.0\n",
            "tifffile==2024.5.22\n",
            "tiktoken==0.7.0\n",
            "tinycss2==1.3.0\n",
            "tokenizers==0.19.1\n",
            "toml==0.10.2\n",
            "tomli==2.0.1\n",
            "toolz==0.12.1\n",
            "torch @ https://download.pytorch.org/whl/cu121/torch-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=0a12aa9aa6bc442dff8823ac8b48d991fd0771562eaa38593f9c8196d65f7007\n",
            "torchaudio @ https://download.pytorch.org/whl/cu121/torchaudio-2.3.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=38b49393f8c322dcaa29d19e5acbf5a0b1978cf1b719445ab670f1fb486e3aa6\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.18.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu121/torchvision-0.18.0%2Bcu121-cp310-cp310-linux_x86_64.whl#sha256=13e1b48dc5ce41ccb8100ab3dd26fdf31d8f1e904ecf2865ac524493013d0df5\n",
            "tornado==6.3.3\n",
            "tqdm==4.66.4\n",
            "traitlets==5.7.1\n",
            "traittypes==0.2.1\n",
            "transformers==4.41.2\n",
            "triton==2.3.0\n",
            "tweepy==4.14.0\n",
            "typer==0.9.4\n",
            "types-pytz==2024.1.0.20240417\n",
            "types-setuptools==70.0.0.20240524\n",
            "typing-inspect==0.9.0\n",
            "typing_extensions==4.12.1\n",
            "tzdata==2024.1\n",
            "tzlocal==5.2\n",
            "uc-micro-py==1.0.3\n",
            "uritemplate==4.1.1\n",
            "urllib3==2.0.7\n",
            "vega-datasets==0.9.0\n",
            "wadllib==1.3.6\n",
            "wasabi==1.1.3\n",
            "wcwidth==0.2.13\n",
            "weasel==0.3.4\n",
            "webcolors==1.13\n",
            "webencodings==0.5.1\n",
            "websocket-client==1.8.0\n",
            "Werkzeug==3.0.3\n",
            "widgetsnbextension==3.6.6\n",
            "wordcloud==1.9.3\n",
            "wrapt==1.14.1\n",
            "xarray==2023.7.0\n",
            "xarray-einstats==0.7.0\n",
            "xgboost==2.0.3\n",
            "xlrd==2.0.1\n",
            "xyzservices==2024.4.0\n",
            "yarl==1.9.4\n",
            "yellowbrick==1.5\n",
            "yfinance==0.2.40\n",
            "zict==3.0.0\n",
            "zipp==3.19.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "import sys\n",
        "from dotenv import load_dotenv, find_dotenv\n",
        "_ = load_dotenv(find_dotenv(\"env\"))\n"
      ],
      "metadata": {
        "id": "RdgYfIeqJUbT"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key  = os.environ['OPENAI_API_KEY']\n"
      ],
      "metadata": {
        "id": "cOvf1ZIYKLfm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key  = os.environ['OPENAI_API_KEY']\n",
        "\n",
        "client = openai.OpenAI(\n",
        "    # This is the default and can be omitted\n",
        "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
        ")\n",
        "\n",
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    chat_completion = client.chat.completions.create(\n",
        "      messages=[{\"role\": \"user\",\"content\": prompt}\n",
        "      ],\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "    )\n",
        "\n",
        "    return chat_completion.choices[0].message.content"
      ],
      "metadata": {
        "id": "XPTSowSeV-fu"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = get_completion(\"What is the capital of Peru?\")"
      ],
      "metadata": {
        "id": "xRx9fezV0eY9"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6LYbLmCO1h5B",
        "outputId": "73556e05-0a15-435a-82d7-8f4582281ffe"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The capital of Peru is Lima.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.graphs import Neo4jGraph\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "y8gMGVylKnNl"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load from environment\n",
        "load_dotenv('env', override=True)\n",
        "NEO4J_URI = os.getenv('NEO4J_URI')\n",
        "NEO4J_USERNAME = os.getenv('NEO4J_USERNAME')\n",
        "NEO4J_PASSWORD = os.getenv('NEO4J_PASSWORD')\n",
        "NEO4J_DATABASE = os.getenv('NEO4J_DATABASE') or 'neo4j'\n",
        "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
        "\n",
        "# Note the code below is unique to this course environment, and not a\n",
        "# standard part of Neo4j's integration with OpenAI. Remove if running\n",
        "# in your own environment.\n",
        "OPENAI_ENDPOINT = os.getenv('OPENAI_BASE_URL') + '/embeddings'\n",
        "\n",
        "# Global constants\n",
        "VECTOR_INDEX_NAME = 'form_10k_chunks'\n",
        "VECTOR_NODE_LABEL = 'Chunk'\n",
        "VECTOR_SOURCE_PROPERTY = 'text'\n",
        "VECTOR_EMBEDDING_PROPERTY = 'textEmbedding'"
      ],
      "metadata": {
        "id": "oibFPV0MMgJq"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")"
      ],
      "metadata": {
        "id": "EHoVOB2HMGiu"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Common data processing\n",
        "import json\n",
        "import textwrap\n",
        "\n",
        "# Langchain\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_community.vectorstores import Neo4jVector\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "ivUnPHeiNpNS"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(textwrap.fill(kg.schema, 60))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UC2CzQdvNaqm",
        "outputId": "85cd05bb-07d2-49d9-885a-85b271729a0d"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties are the following:  Relationship properties\n",
            "are the following:  The relationships are the following:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_name = \"./data/form10k/0000950170-23-027948.json\""
      ],
      "metadata": {
        "id": "2E55fj05MTtW"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_as_object = json.load(open(first_file_name))"
      ],
      "metadata": {
        "id": "wZwW1Dk-Mi_E"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(first_file_as_object)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "faItwLEgeU_v",
        "outputId": "47d8e0e6-4800-4294-db20-15ab3a5208aa"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for k,v in first_file_as_object.items():\n",
        "    print(k, type(v))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pf3i4FoLeYbw",
        "outputId": "7a9ed93e-e0f0-48a8-d823-fc0c51a0291e"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "item1 <class 'str'>\n",
            "item1a <class 'str'>\n",
            "item7 <class 'str'>\n",
            "item7a <class 'str'>\n",
            "cik <class 'str'>\n",
            "cusip6 <class 'str'>\n",
            "cusip <class 'list'>\n",
            "names <class 'list'>\n",
            "source <class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text = first_file_as_object['item1']"
      ],
      "metadata": {
        "id": "Epqa-a3xec2_"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text[0:1500]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "LebHjKMCefvx",
        "outputId": "7d3c0c6d-2148-48df-d483-d4177064fe63"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud envir'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Form 10-K sections into chunks\n",
        "\n",
        "*   Set up text splitter using LangChain\n",
        "*   For now, split only the text from the \"item 1\" section\n",
        "\n"
      ],
      "metadata": {
        "id": "7EeN5EJue9lw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 2000,\n",
        "    chunk_overlap  = 200,\n",
        "    length_function = len,\n",
        "    is_separator_regex = False,\n",
        ")"
      ],
      "metadata": {
        "id": "jE8_xz58fvNs"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text_chunks = text_splitter.split_text(item1_text)"
      ],
      "metadata": {
        "id": "lm6FnndNf-Wt"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(item1_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kPM0UYlgBLX",
        "outputId": "4ffece9d-53c5-4f4b-b91e-70d367ddcf51"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(item1_text_chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLgyd9UKgXFq",
        "outputId": "e9d070ac-701b-4087-d8c8-16a2b36271e5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "item1_text_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "e3kYqeVogZie",
        "outputId": "e0ac9c88-5c91-4f4c-db58-cfcd9ee69fb2"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Set up helper function to chunk all sections of the Form 10-K\n",
        "* You'll limit the number of chunks in each section to 20 to speed things up\n"
      ],
      "metadata": {
        "id": "AbfqC34Ygfeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_form10k_data_from_file(file):\n",
        "    chunks_with_metadata = [] # use this to accumlate chunk records\n",
        "    file_as_object = json.load(open(file)) # open the json file\n",
        "    for item in ['item1','item1a','item7','item7a']: # pull these keys from the json\n",
        "        print(f'Processing {item} from {file}')\n",
        "        item_text = file_as_object[item] # grab the text of the item\n",
        "        item_text_chunks = text_splitter.split_text(item_text) # split the text into chunks\n",
        "        chunk_seq_id = 0\n",
        "        for chunk in item_text_chunks[:20]: # only take the first 20 chunks\n",
        "            form_id = file[file.rindex('/') + 1:file.rindex('.')] # extract form id from file name\n",
        "            # finally, construct a record with metadata and the chunk text\n",
        "            chunks_with_metadata.append({\n",
        "                'text': chunk,\n",
        "                # metadata from looping...\n",
        "                'f10kItem': item,\n",
        "                'chunkSeqId': chunk_seq_id,\n",
        "                # constructed metadata...\n",
        "                'formId': f'{form_id}', # pulled from the filename\n",
        "                'chunkId': f'{form_id}-{item}-chunk{chunk_seq_id:04d}',\n",
        "                # metadata from file...\n",
        "                'names': file_as_object['names'],\n",
        "                'cik': file_as_object['cik'],\n",
        "                'cusip6': file_as_object['cusip6'],\n",
        "                'source': file_as_object['source'],\n",
        "            })\n",
        "            chunk_seq_id += 1\n",
        "        print(f'\\tSplit into {chunk_seq_id} chunks')\n",
        "    return chunks_with_metadata"
      ],
      "metadata": {
        "id": "a4Sa8lSbgn9n"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks = split_form10k_data_from_file(first_file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfZRoAYogfTb",
        "outputId": "77de4354-8c43-4f78-e381-7c3df6e42288"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing item1 from ./data/form10k/0000950170-23-027948.json\n",
            "\tSplit into 20 chunks\n",
            "Processing item1a from ./data/form10k/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n",
            "Processing item7 from ./data/form10k/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n",
            "Processing item7a from ./data/form10k/0000950170-23-027948.json\n",
            "\tSplit into 1 chunks\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first_file_chunks[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3d01k9Sg1Qm",
        "outputId": "71ff4239-1c61-490e-bc2c-fa8389f2315e"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.',\n",
              " 'f10kItem': 'item1',\n",
              " 'chunkSeqId': 0,\n",
              " 'formId': '0000950170-23-027948',\n",
              " 'chunkId': '0000950170-23-027948-item1-chunk0000',\n",
              " 'names': ['Netapp Inc', 'NETAPP INC'],\n",
              " 'cik': '1002047',\n",
              " 'cusip6': '64110D',\n",
              " 'source': 'https://www.sec.gov/Archives/edgar/data/1002047/000095017023027948/0000950170-23-027948-index.htm'}"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create graph nodes using text chunks"
      ],
      "metadata": {
        "id": "brmJc_qeg7G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merge_chunk_node_query = \"\"\"\n",
        "MERGE(mergedChunk:Chunk {chunkId: $chunkParam.chunkId})\n",
        "    ON CREATE SET\n",
        "        mergedChunk.names = $chunkParam.names,\n",
        "        mergedChunk.formId = $chunkParam.formId,\n",
        "        mergedChunk.cik = $chunkParam.cik,\n",
        "        mergedChunk.cusip6 = $chunkParam.cusip6,\n",
        "        mergedChunk.source = $chunkParam.source,\n",
        "        mergedChunk.f10kItem = $chunkParam.f10kItem,\n",
        "        mergedChunk.chunkSeqId = $chunkParam.chunkSeqId,\n",
        "        mergedChunk.text = $chunkParam.text\n",
        "RETURN mergedChunk\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FJ5wBCsig9-h"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg = Neo4jGraph(\n",
        "    url=NEO4J_URI, username=NEO4J_USERNAME, password=NEO4J_PASSWORD, database=NEO4J_DATABASE\n",
        ")"
      ],
      "metadata": {
        "id": "LCbqaIXchD-n"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(merge_chunk_node_query,\n",
        "         params={'chunkParam':first_file_chunks[0]})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XtINEcRfhHZp",
        "outputId": "a460ba58-7bd7-4959-ba81-5ff5d5a8b4b1"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'mergedChunk': {'formId': '0000950170-23-027948',\n",
              "   'f10kItem': 'item1',\n",
              "   'names': ['Netapp Inc', 'NETAPP INC'],\n",
              "   'cik': '1002047',\n",
              "   'cusip6': '64110D',\n",
              "   'source': 'https://www.sec.gov/Archives/edgar/data/1002047/000095017023027948/0000950170-23-027948-index.htm',\n",
              "   'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.',\n",
              "   'chunkId': '0000950170-23-027948-item1-chunk0000',\n",
              "   'chunkSeqId': 0}}]"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "CREATE CONSTRAINT unique_chunk IF NOT EXISTS\n",
        "    FOR (c:Chunk) REQUIRE c.chunkId IS UNIQUE\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tso9z-3chKN0",
        "outputId": "46de960a-eecb-46f3-e91e-1d86533eec79"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVzSqIkghLab",
        "outputId": "ead4b986-d1e8-4c5d-89d1-7ca639d9592c"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 0,\n",
              "  'name': 'index_343aff4e',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 1,\n",
              "  'name': 'index_f7700477',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'RELATIONSHIP',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 2,\n",
              "  'name': 'unique_chunk',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'RANGE',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['chunkId'],\n",
              "  'indexProvider': 'range-1.0',\n",
              "  'owningConstraint': 'unique_chunk',\n",
              "  'lastRead': None,\n",
              "  'readCount': None}]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Loop through and create nodes for all chunks\n",
        "* Should create 23 nodes because you set a limit of 20 chunks in the text splitting function above"
      ],
      "metadata": {
        "id": "41rPipPfhVeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "node_count = 0\n",
        "for chunk in first_file_chunks:\n",
        "    print(f\"Creating `:Chunk` node for chunk ID {chunk['chunkId']}\")\n",
        "    kg.query(merge_chunk_node_query,\n",
        "            params={\n",
        "                'chunkParam': chunk\n",
        "            })\n",
        "    node_count += 1\n",
        "print(f\"Created {node_count} nodes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7Hra873haXc",
        "outputId": "7b85ab95-9049-43f1-cf60-3ecb3b1ff9de"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0001\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0002\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0003\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0004\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0005\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0006\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0007\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0008\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0009\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0010\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0011\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0012\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0013\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0014\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0015\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0016\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0017\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0018\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1-chunk0019\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item1a-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item7-chunk0000\n",
            "Creating `:Chunk` node for chunk ID 0000950170-23-027948-item7a-chunk0000\n",
            "Created 23 nodes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         MATCH (n)\n",
        "         RETURN count(n) as nodeCount\n",
        "         \"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AciVTHujhdsg",
        "outputId": "aaa0d4a2-ea30-40e9-bfa2-5c79be4b1f2f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'nodeCount': 23}]"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a vector index"
      ],
      "metadata": {
        "id": "KXF5zDulhpwx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "         CREATE VECTOR INDEX `form_10k_chunks` IF NOT EXISTS\n",
        "          FOR (c:Chunk) ON (c.textEmbedding)\n",
        "          OPTIONS { indexConfig: {\n",
        "            `vector.dimensions`: 1536,\n",
        "            `vector.similarity_function`: 'cosine'\n",
        "         }}\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1jofkofhsOY",
        "outputId": "c4db96e8-9b88-41e8-99f3-eb7d949fbfa7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"SHOW INDEXES\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNuUeb7Hhv36",
        "outputId": "66a5268f-0d45-4ff4-ad26-518f75a4efdf"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 4,\n",
              "  'name': 'form_10k_chunks',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'VECTOR',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['textEmbedding'],\n",
              "  'indexProvider': 'vector-2.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': None},\n",
              " {'id': 0,\n",
              "  'name': 'index_343aff4e',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 1,\n",
              "  'name': 'index_f7700477',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'LOOKUP',\n",
              "  'entityType': 'RELATIONSHIP',\n",
              "  'labelsOrTypes': None,\n",
              "  'properties': None,\n",
              "  'indexProvider': 'token-lookup-1.0',\n",
              "  'owningConstraint': None,\n",
              "  'lastRead': None,\n",
              "  'readCount': 0},\n",
              " {'id': 2,\n",
              "  'name': 'unique_chunk',\n",
              "  'state': 'ONLINE',\n",
              "  'populationPercent': 100.0,\n",
              "  'type': 'RANGE',\n",
              "  'entityType': 'NODE',\n",
              "  'labelsOrTypes': ['Chunk'],\n",
              "  'properties': ['chunkId'],\n",
              "  'indexProvider': 'range-1.0',\n",
              "  'owningConstraint': 'unique_chunk',\n",
              "  'lastRead': neo4j.time.DateTime(2024, 6, 11, 18, 18, 55, 773000000, tzinfo=<UTC>),\n",
              "  'readCount': 67}]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate embedding vectors for chunks and populate index\n",
        "* This query calculates the embedding vector and stores it as a property called textEmbedding on each Chunk node."
      ],
      "metadata": {
        "id": "Jn6px91eh8xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kg.query(\"\"\"\n",
        "    MATCH (chunk:Chunk) WHERE chunk.textEmbedding IS NULL\n",
        "    WITH chunk, genai.vector.encode(\n",
        "      chunk.text,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey,\n",
        "        endpoint: $openAiEndpoint\n",
        "      }) AS vector\n",
        "    CALL db.create.setNodeVectorProperty(chunk, \"textEmbedding\", vector)\n",
        "    \"\"\",\n",
        "    params={\"openAiApiKey\":OPENAI_API_KEY, \"openAiEndpoint\": OPENAI_ENDPOINT} )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uyzBKz1iA7D",
        "outputId": "3cb223e9-a0c1-44b6-a41f-5a64862a1a18"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kg.refresh_schema()\n",
        "print(kg.schema)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2h41rAYiGNw",
        "outputId": "73fe1cd6-0e89-4c51-f66c-f784d420dfc8"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node properties are the following:\n",
            "Chunk {chunkId: STRING, names: LIST, formId: STRING, cik: STRING, cusip6: STRING, source: STRING, f10kItem: STRING, chunkSeqId: INTEGER, text: STRING, textEmbedding: LIST}\n",
            "Relationship properties are the following:\n",
            "\n",
            "The relationships are the following:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Use similarity search to find relevant chunks\n",
        "* Setup a help function to perform similarity search using the vector index"
      ],
      "metadata": {
        "id": "ne0kYAkMik5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def neo4j_vector_search(question):\n",
        "  \"\"\"Search for similar nodes using the Neo4j vector index\"\"\"\n",
        "  vector_search_query = \"\"\"\n",
        "    WITH genai.vector.encode(\n",
        "      $question,\n",
        "      \"OpenAI\",\n",
        "      {\n",
        "        token: $openAiApiKey,\n",
        "        endpoint: $openAiEndpoint\n",
        "      }) AS question_embedding\n",
        "    CALL db.index.vector.queryNodes($index_name, $top_k, question_embedding) yield node, score\n",
        "    RETURN score, node.text AS text\n",
        "  \"\"\"\n",
        "  similar = kg.query(vector_search_query,\n",
        "                     params={\n",
        "                      'question': question,\n",
        "                      'openAiApiKey':OPENAI_API_KEY,\n",
        "                      'openAiEndpoint': OPENAI_ENDPOINT,\n",
        "                      'index_name':VECTOR_INDEX_NAME,\n",
        "                      'top_k': 10})\n",
        "  return similar"
      ],
      "metadata": {
        "id": "V0FL2aqiipke"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results = neo4j_vector_search(\n",
        "    'In a single sentence, tell me about Netapp.'\n",
        ")"
      ],
      "metadata": {
        "id": "10-3xxE0i2CD"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "search_results[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3u_IjxUi2-Q",
        "outputId": "02514e50-566e-4bf4-9309-21ff0879d19b"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.9356337785720825,\n",
              " 'text': '>Item 1.  \\nBusiness\\n\\n\\nOverview\\n\\n\\nNetApp, Inc. (NetApp, we, us or the Company) is a global cloud-led, data-centric software company. We were incorporated in 1992 and are headquartered in San Jose, California. Building on more than three decades of innovation, we give customers the freedom to manage applications and data across hybrid multicloud environments. Our portfolio of cloud services, and storage infrastructure, powered by intelligent data management software, enables applications to run faster, more reliably, and more securely, all at a lower cost.\\n\\n\\nOur opportunity is defined by the durable megatrends of data-driven digital and cloud transformations. NetApp helps organizations meet the complexities created by rapid data and cloud growth, multi-cloud management, and the adoption of next-generation technologies, such as AI, Kubernetes, and modern databases. Our modern approach to hybrid, multicloud infrastructure and data management, which we term ‘evolved cloud’, provides customers the ability to leverage data across their entire estate with simplicity, security, and sustainability which increases our relevance and value to our customers.\\n\\n\\nIn an evolved cloud state, the cloud is fully integrated into an organization’s architecture and operations. Data centers and clouds are seamlessly united and hybrid multicloud operations are simplified, with consistency and observability across environments. The key benefits NetApp brings to an organization’s hybrid multicloud environment are:\\n\\n\\n•\\nOperational simplicity: NetApp’s use of open source, open architectures and APIs, microservices, and common capabilities and data services facilitate the creation of applications that can run anywhere.\\n\\n\\n•\\nFlexibility and consistency: NetApp makes moving data and applications between environments seamless through a common storage foundation across on-premises and multicloud environments.'}"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up a LangChain RAG workflow to chat with the form¶"
      ],
      "metadata": {
        "id": "OuJBVVY2kiFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neo4j_vector_store = Neo4jVector.from_existing_graph(\n",
        "    embedding=OpenAIEmbeddings(),\n",
        "    url=NEO4J_URI,\n",
        "    username=NEO4J_USERNAME,\n",
        "    password=NEO4J_PASSWORD,\n",
        "    index_name=VECTOR_INDEX_NAME,\n",
        "    node_label=VECTOR_NODE_LABEL,\n",
        "    text_node_properties=[VECTOR_SOURCE_PROPERTY],\n",
        "    embedding_node_property=VECTOR_EMBEDDING_PROPERTY,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsHm_x-bkjyY",
        "outputId": "48512bfc-2fcf-431c-ec85-cf0cc338f818"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:neo4j.notifications:Received notification from DBMS server: {severity: WARNING} {code: Neo.ClientNotification.Statement.FeatureDeprecationWarning} {category: DEPRECATION} {title: This feature is deprecated and will be removed in future versions.} {description: The query used a deprecated procedure. ('db.create.setVectorProperty' has been replaced by 'db.create.setNodeVectorProperty')} {position: line: 1, column: 67, offset: 66} for query: \"UNWIND $data AS row MATCH (n:`Chunk`) WHERE elementId(n) = row.id CALL db.create.setVectorProperty(n, 'textEmbedding', row.embedding) YIELD node RETURN count(*)\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = neo4j_vector_store.as_retriever()"
      ],
      "metadata": {
        "id": "4NNTeCd0kq31"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Set up a RetrievalQAWithSourcesChain to carry out question answering"
      ],
      "metadata": {
        "id": "KRTeEQN1kxr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
        "    ChatOpenAI(temperature=0),\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")"
      ],
      "metadata": {
        "id": "dCv_yXKVkwmY"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prettychain(question: str) -> str:\n",
        "    \"\"\"Pretty print the chain's response to a question\"\"\"\n",
        "    response = chain({\"question\": question},\n",
        "        return_only_outputs=True,)\n",
        "    print(textwrap.fill(response['answer'], 60))"
      ],
      "metadata": {
        "id": "wDLSbDzUk6Rw"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is Netapp's primary business?\""
      ],
      "metadata": {
        "id": "6cUDOTZ-k9mP"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prettychain(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5qRh0FBnlAdN",
        "outputId": "2994cd5c-33a9-401c-a331-832fc99872b4"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NetApp's primary business is enterprise storage and data\n",
            "management, cloud storage, and cloud operations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prettychain(\"\"\"\n",
        "    Tell me about Apple.\n",
        "    Limit your answer to a single sentence.\n",
        "\"\"\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKlAj4pSla-z",
        "outputId": "42fd2c4c-b0de-4d18-81da-f8ee7b19688a"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple is a global cloud-led, data-centric software company\n",
            "headquartered in San Jose, California, that provides\n",
            "customers with the freedom to manage applications and data\n",
            "across hybrid multicloud environments.\n"
          ]
        }
      ]
    }
  ]
}